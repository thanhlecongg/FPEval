# FPEval: A Holistic Evaluation Framework for Code Generation in Functional Programming

[![Build and test](https://github.com/thanhlecongg/FormalBench/actions/workflows/build_and_test.yml/badge.svg)]()
[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Release](https://img.shields.io/badge/Release-0.1.0-orange.svg)]()
[![Dataset](https://img.shields.io/badge/Dataset-v1.0-yellow.svg)]()


This repository contains evaluation infrastructure for FPEval including FPBench benchmark, evaluation infrastructures and wrappers for calling LLMs. If you found this repository to be useful, please cite our research paper:

```
@article{le2025can,
  title={Perish or Flourish? A Holistic Evaluation of Large Language Models for Code Generation in Functional Programming},
  author={Lang, Nguyet-Anh, and Lang, Eric and Le-Cong, Thanh and Le, Bach and Huynh, Quyet-Thang},
  year={2025},
  url={https://github.com/thanhlecongg/FPEval/}
}
```
